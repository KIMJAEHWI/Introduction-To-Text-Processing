{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Packages\n",
    "!pip install sentence_transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from Korpora import Korpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : TRAC (https://trac.edgewall.org/)\n",
      "    Repository : http://opus.nlpl.eu/OpenSubtitles-v2018.php\n",
      "    References :\n",
      "        - P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora\n",
      "          from Movie and TV Subtitles. In Proceedings of the 10th International Conference on\n",
      "          Language Resources and Evaluation (LREC 2016)\n",
      "\n",
      "    This is a new collection of translated movie subtitles from http://www.opensubtitles.org/.\n",
      "\n",
      "    [[ IMPORTANT ]]\n",
      "    If you use the OpenSubtitle corpus: Please, add a link to http://www.opensubtitles.org/\n",
      "    to your website and to your reports and publications produced with the data!\n",
      "    I promised this when I got the data from the providers of that website!\n",
      "\n",
      "    This is a slightly cleaner version of the subtitle collection using improved sentence alignment\n",
      "    and better language checking.\n",
      "\n",
      "    62 languages, 1,782 bitexts\n",
      "    total number of files: 3,735,070\n",
      "    total number of tokens: 22.10G\n",
      "    total number of sentence fragments: 3.35G\n",
      "\n",
      "    [[ NOTICE ]]\n",
      "    In original data, the source language is `en` and target language is `ko`. However in Korpora,\n",
      "    we change the language pair so that source language is `ko` and target language is `en`.\n",
      "\n",
      "    # License\n",
      "    Open Data. Details in https://opendefinition.org/od/2.1/en/\n",
      "\n",
      "[Korpora] Corpus `open_subtitles` is already installed at C:\\Users\\pilot\\Korpora\\open_subtitles\\en-ko.tmx.gz\n",
      "[Korpora] Corpus `open_subtitles` is already installed at C:\\Users\\pilot\\Korpora\\open_subtitles\\en-ko.tmx\n"
     ]
    }
   ],
   "source": [
    "corpus = Korpora.load('open_subtitles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\")\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver', options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class google_translation:\n",
    "    def __init__(self, input_text):\n",
    "        import urllib.parse\n",
    "\n",
    "        # 한글 퍼센트 인코딩\n",
    "        self.url_input = urllib.parse.quote(input_text.encode('utf8'))\n",
    "\n",
    "        # 키워드를 포함하는 url\n",
    "        self.url = f'https://translate.google.co.kr/?hl=ko&sl=ko&tl=en&text={self.url_input}&op=translate'\n",
    "\n",
    "        # 번역 결과를 가리키는 xpath\n",
    "        self.xpath = '/html/body/c-wiz/div/div[2]/c-wiz/div[2]/c-wiz/div[1]/div[2]/div[3]/c-wiz[2]/div[8]/div/div[1]/span[1]/span/span'\n",
    "    \n",
    "    def get_translation(self):\n",
    "\n",
    "        # 웹페이지 on\n",
    "        driver.get(self.url)\n",
    "\n",
    "        # 웹페이지 로딩까지 최대 10초 대기\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        # 웹페이지에서 해당 위치의 값 불러와 저장\n",
    "        output_text_list = driver.find_elements(By.XPATH, self.xpath)\n",
    "\n",
    "        # 텍스트만 반환\n",
    "        return output_text_list[0].text\n",
    "\n",
    "class papago_translation(google_translation):\n",
    "    def __init__(self, input_text):\n",
    "        import urllib\n",
    "\n",
    "        self.url_input = urllib.parse.quote(input_text)\n",
    "        self.url = f'https://papago.naver.com/?sk=ko&tk=en&st={self.url_input}'\n",
    "        self.xpath = '/html/body/div/div/div[1]/section/div/div[1]/div[2]/div/div[5]/div/span'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf7a1f917c04fdb92a70e4b0c7fc0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2324/2086546043.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# lists of sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtrans_google\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoogle_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkor_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mtrans_papago\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpapago_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkor_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0msubtitle_eng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meng_txt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2324/402577909.py\u001b[0m in \u001b[0;36mget_translation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# 텍스트만 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput_text_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mpapago_translation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoogle_translation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "data_dict = {'subtitle_kor': [],\n",
    "             'subtitle_eng': [], \n",
    "             'trans_google': [], \n",
    "             'trans_papago': [], \n",
    "             'sim_google': [], \n",
    "             'sim_papago': [], \n",
    "             'unigram_overlap_google': [], \n",
    "             'unigram_overlap_papago': [], \n",
    "             'BLEU2_google': [], \n",
    "             'BLEU2_papago': []}\n",
    "\n",
    "# Data we use\n",
    "start_index = 2500\n",
    "end_index = 5000\n",
    "whole_data = list(zip(corpus.get_all_texts(), corpus.get_all_pairs()))\n",
    "\n",
    "for kor_txt, eng_txt in tqdm(whole_data[start_index:end_index]):\n",
    "    subtitle_kor = kor_txt\n",
    "    \n",
    "    # lists of sentences\n",
    "    trans_google = google_translation(kor_txt).get_translation()\n",
    "    trans_papago = papago_translation(kor_txt).get_translation()\n",
    "    subtitle_eng = eng_txt\n",
    "\n",
    "    # Compute embedding for lists\n",
    "    embeddings_google = model.encode([trans_google], convert_to_tensor=True)\n",
    "    embeddings_papago = model.encode([trans_papago], convert_to_tensor=True)\n",
    "    embeddings_Target = model.encode([subtitle_eng], convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine-similarits\n",
    "    sim_google = util.cos_sim(embeddings_google, embeddings_Target).item()\n",
    "    sim_papago = util.cos_sim(embeddings_papago, embeddings_Target).item()\n",
    "    \n",
    "    # Unigram overlap\n",
    "    tokenized_google = [word.lower() for word in tokenizer.tokenize(trans_google.replace('-', ' ')) if word not in '.,:']\n",
    "    tokenized_papago = [word.lower() for word in tokenizer.tokenize(trans_papago.replace('-', ' ')) if word not in '.,:']\n",
    "    tokenized_target = [word.lower() for word in tokenizer.tokenize(subtitle_eng.replace('-', ' ')) if word not in '.,:']\n",
    "    \n",
    "    unigram_overlap_google = sentence_bleu([tokenized_target], tokenized_google, weights=(1,))\n",
    "    unigram_overlap_papago = sentence_bleu([tokenized_target], tokenized_papago, weights=(1,))\n",
    "    \n",
    "    # 2-gram overlap with smoothing\n",
    "    BLEU2_google = sentence_bleu([tokenized_target], tokenized_google, weights=(.5,.5), smoothing_function=SmoothingFunction().method1)\n",
    "    BLEU2_papago = sentence_bleu([tokenized_target], tokenized_papago, weights=(.5,.5), smoothing_function=SmoothingFunction().method1)\n",
    "    \n",
    "    # Construct Data Dictionary\n",
    "    for key in data_dict:\n",
    "        data_dict[key].append(eval(f'{key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtitle_kor</th>\n",
       "      <th>subtitle_eng</th>\n",
       "      <th>trans_google</th>\n",
       "      <th>trans_papago</th>\n",
       "      <th>sim_google</th>\n",
       "      <th>sim_papago</th>\n",
       "      <th>unigram_overlap_google</th>\n",
       "      <th>unigram_overlap_papago</th>\n",
       "      <th>BLEU2_google</th>\n",
       "      <th>BLEU2_papago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...</td>\n",
       "      <td>Through the snow and sleet and hail, through t...</td>\n",
       "      <td>Even if the snowfall falls and the snow and sl...</td>\n",
       "      <td>Heavy snow, hail, sleet, blizzard, strong wind...</td>\n",
       "      <td>0.476623</td>\n",
       "      <td>0.718432</td>\n",
       "      <td>0.317082</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.217699</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!</td>\n",
       "      <td>ever faithful, ever true, nothing stops him, h...</td>\n",
       "      <td>Who will stop the way to our constant errands.</td>\n",
       "      <td>Who will stop our constant errand boy, Mr. Stork?</td>\n",
       "      <td>0.222570</td>\n",
       "      <td>0.229132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>황새 아저씨를 기다리세요</td>\n",
       "      <td>Look out for Mr Stork That persevering chap</td>\n",
       "      <td>Wait for the stork</td>\n",
       "      <td>Wait for Mr. Stork</td>\n",
       "      <td>0.600879</td>\n",
       "      <td>0.705570</td>\n",
       "      <td>0.183940</td>\n",
       "      <td>0.183940</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.047493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>찾아와 선물을 주실 거예요</td>\n",
       "      <td>He'll come along and drop a bundle in your lap</td>\n",
       "      <td>You will come and give you a gift</td>\n",
       "      <td>They'll come and give me a present</td>\n",
       "      <td>0.411141</td>\n",
       "      <td>0.367302</td>\n",
       "      <td>0.257733</td>\n",
       "      <td>0.343645</td>\n",
       "      <td>0.050304</td>\n",
       "      <td>0.183686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가난하든 부자이든 상관이 없답니다</td>\n",
       "      <td>You may be poor or rich It doesn't matter which</td>\n",
       "      <td>It doesn't matter whether it's poor or rich</td>\n",
       "      <td>It doesn't matter if you're poor or rich</td>\n",
       "      <td>0.732840</td>\n",
       "      <td>0.813101</td>\n",
       "      <td>0.633386</td>\n",
       "      <td>0.723870</td>\n",
       "      <td>0.564265</td>\n",
       "      <td>0.603225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>개가 아니라 우리가 말하는 나입니다.</td>\n",
       "      <td>It's me we're talking about, not dogs.</td>\n",
       "      <td>It's not a dog, but I say.</td>\n",
       "      <td>It's not the dog, it's me we're talking about.</td>\n",
       "      <td>0.705835</td>\n",
       "      <td>0.898236</td>\n",
       "      <td>0.330936</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.204258</td>\n",
       "      <td>0.603023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>오늘 내가 어떻게 보는 것이 중요합니다.</td>\n",
       "      <td>It's important how I look today.</td>\n",
       "      <td>It is important to see how I see it today.</td>\n",
       "      <td>It's important how I look today.</td>\n",
       "      <td>0.705796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>나는 결혼 할거야.</td>\n",
       "      <td>I'm gonna get married.</td>\n",
       "      <td>I'm going to get married.</td>\n",
       "      <td>I'm gonna get married.</td>\n",
       "      <td>0.948955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>결혼 했니?</td>\n",
       "      <td>Married, you?</td>\n",
       "      <td>Are you married?</td>\n",
       "      <td>Are you married?</td>\n",
       "      <td>0.817232</td>\n",
       "      <td>0.817232</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.158114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>네, 저요.</td>\n",
       "      <td>Yes, me.</td>\n",
       "      <td>Yes, me.</td>\n",
       "      <td>Yes, me.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           subtitle_kor  \\\n",
       "0     폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...   \n",
       "1                  우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!   \n",
       "2                                         황새 아저씨를 기다리세요   \n",
       "3                                        찾아와 선물을 주실 거예요   \n",
       "4                                    가난하든 부자이든 상관이 없답니다   \n",
       "...                                                 ...   \n",
       "2495                               개가 아니라 우리가 말하는 나입니다.   \n",
       "2496                             오늘 내가 어떻게 보는 것이 중요합니다.   \n",
       "2497                                         나는 결혼 할거야.   \n",
       "2498                                             결혼 했니?   \n",
       "2499                                             네, 저요.   \n",
       "\n",
       "                                           subtitle_eng  \\\n",
       "0     Through the snow and sleet and hail, through t...   \n",
       "1     ever faithful, ever true, nothing stops him, h...   \n",
       "2           Look out for Mr Stork That persevering chap   \n",
       "3        He'll come along and drop a bundle in your lap   \n",
       "4       You may be poor or rich It doesn't matter which   \n",
       "...                                                 ...   \n",
       "2495             It's me we're talking about, not dogs.   \n",
       "2496                   It's important how I look today.   \n",
       "2497                             I'm gonna get married.   \n",
       "2498                                      Married, you?   \n",
       "2499                                           Yes, me.   \n",
       "\n",
       "                                           trans_google  \\\n",
       "0     Even if the snowfall falls and the snow and sl...   \n",
       "1        Who will stop the way to our constant errands.   \n",
       "2                                    Wait for the stork   \n",
       "3                     You will come and give you a gift   \n",
       "4           It doesn't matter whether it's poor or rich   \n",
       "...                                                 ...   \n",
       "2495                         It's not a dog, but I say.   \n",
       "2496         It is important to see how I see it today.   \n",
       "2497                          I'm going to get married.   \n",
       "2498                                   Are you married?   \n",
       "2499                                           Yes, me.   \n",
       "\n",
       "                                           trans_papago  sim_google  \\\n",
       "0     Heavy snow, hail, sleet, blizzard, strong wind...    0.476623   \n",
       "1     Who will stop our constant errand boy, Mr. Stork?    0.222570   \n",
       "2                                    Wait for Mr. Stork    0.600879   \n",
       "3                    They'll come and give me a present    0.411141   \n",
       "4              It doesn't matter if you're poor or rich    0.732840   \n",
       "...                                                 ...         ...   \n",
       "2495     It's not the dog, it's me we're talking about.    0.705835   \n",
       "2496                   It's important how I look today.    0.705796   \n",
       "2497                             I'm gonna get married.    0.948955   \n",
       "2498                                   Are you married?    0.817232   \n",
       "2499                                           Yes, me.    1.000000   \n",
       "\n",
       "      sim_papago  unigram_overlap_google  unigram_overlap_papago  \\\n",
       "0       0.718432                0.317082                0.063503   \n",
       "1       0.229132                0.000000                0.000000   \n",
       "2       0.705570                0.183940                0.183940   \n",
       "3       0.367302                0.257733                0.343645   \n",
       "4       0.813101                0.633386                0.723870   \n",
       "...          ...                     ...                     ...   \n",
       "2495    0.898236                0.330936                0.666667   \n",
       "2496    1.000000                0.500000                1.000000   \n",
       "2497    1.000000                0.666667                1.000000   \n",
       "2498    0.817232                0.750000                0.750000   \n",
       "2499    1.000000                1.000000                1.000000   \n",
       "\n",
       "      BLEU2_google  BLEU2_papago  \n",
       "0         0.217699      0.008001  \n",
       "1         0.000000      0.000000  \n",
       "2         0.047493      0.047493  \n",
       "3         0.050304      0.183686  \n",
       "4         0.564265      0.603225  \n",
       "...            ...           ...  \n",
       "2495      0.204258      0.603023  \n",
       "2496      0.235702      1.000000  \n",
       "2497      0.516398      1.000000  \n",
       "2498      0.158114      0.158114  \n",
       "2499      1.000000      1.000000  \n",
       "\n",
       "[2500 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_eda = pd.DataFrame(data_dict)\n",
    "data_for_eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_eda.to_csv('Score_Data.csv',index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
